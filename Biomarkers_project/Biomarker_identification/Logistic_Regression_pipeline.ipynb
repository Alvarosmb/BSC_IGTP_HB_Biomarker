{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4b35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score, classification_report\n",
    "from sklearn import tree\n",
    "from statannot import add_stat_annotation\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a1752",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aef9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Original Datasets\n",
    "df = pd.read_csv()\n",
    "columns = df.columns\n",
    "columns = [i.replace(\" \", \"_\") for i in columns]\n",
    "df.columns = columns\n",
    "df = df.loc[df[\"Diagnosis_simplified\"].isin([\"HB\", \"HCC\", \"NOS\"])]\n",
    "subset[\"Diagnosis_simplified\"] = df[\"Diagnosis_simplified\"]\n",
    "variables = subset.columns.tolist()[:-1]\n",
    "variables_bx = []\n",
    "variables_SR = []\n",
    "\n",
    "array_split = list(map(lambda x: x.split(\"_\"), variables))\n",
    "\n",
    "for i in range(len(array_split)):\n",
    "    if \"bx\" in array_split[i]:\n",
    "        variables_bx.append(variables[i])\n",
    "    elif \"SR\" in array_split[i]:\n",
    "        variables_SR.append(variables[i])\n",
    "if \"Diagnosis_simplifed\" not in variables_bx:\n",
    "    variables_bx.append(\"Diagnosis_simplified\")\n",
    "df_nano_bx = df[variables_bx].dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d9a324",
   "metadata": {},
   "source": [
    "### Data anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89cf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the original and new column names\n",
    "dict_genes = {}\n",
    "\n",
    "# Iterate over the columns of the DataFrame\n",
    "for i, col in enumerate(df_nano_bx.columns):\n",
    "    # Create the new column name as \"BSC_BM\" followed by the index\n",
    "    new_col = f\"BSC_BM{i+1}\"\n",
    "    # Add the original and new column names to the dictionary\n",
    "    dict_genes[col] = new_col\n",
    "    # Rename the column in the DataFrame\n",
    "    df_nano_bx.rename(columns={col: new_col}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92720c",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b342f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regression_fun(X_data,Y_data):\n",
    "    #Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    # transform data\n",
    "    X_fitted = scaler.fit_transform(X)\n",
    "    # create loocv procedure\n",
    "    cv = LeaveOneOut()\n",
    "    # enumerate splits\n",
    "    y_true, y_pred = list(), list()\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # split data\n",
    "        X_train, X_test = X_fitted[train_ix, :], X_fitted[test_ix, :]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        # fit model\n",
    "        model = LogisticRegression(class_weight=\"balanced\", solver='lbfgs', C = 0.1, penalty=\"l2\", max_iter = 100000) \n",
    "        model.fit(X_train, y_train)\n",
    "        # evaluate model\n",
    "        yhat = model.predict(X_test)\n",
    "        y_true.append(y_test[0])\n",
    "        y_pred.append(yhat[0])\n",
    "        # calculate F1 score\n",
    "        score_f1 = f1_score(y_true,y_pred,average='weighted')\n",
    "        score_precision = precision_score(y_true,y_pred,average='weighted', zero_division=0)\n",
    "        score_recall = recall_score(y_true,y_pred,average='weighted', zero_division=0)\n",
    "\n",
    "    return(score_f1, score_precision, score_recall, y_true, y_pred)\n",
    "        \n",
    "def combinations_fun(features):\n",
    "    var_names_combs = []\n",
    "    for j in range(len(features)+1):\n",
    "        combs = combinations(features,j )\n",
    "        for i in combs:\n",
    "            var_names_combs.append(i)\n",
    "    var_names_combs = var_names_combs[1:]\n",
    "    for i in range(len(var_names_combs)):\n",
    "        var_names_combs[i] =  [s.replace(\")\", \"\") for s in var_names_combs[i]]\n",
    "        var_names_combs[i] =  [s.replace(\"(\", \"\") for s in var_names_combs[i]]\n",
    "    return(var_names_combs)\n",
    "\n",
    "def confusion_matrix_fun(df):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10), squeeze=False)\n",
    "    axes_list = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "    for i, num in zip(range(df.shape[0]), axes_list):\n",
    "        cf_matrix = confusion_matrix(df[\"y_true\"][i], df[\"y_pred\"][i])\n",
    "        group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                                cf_matrix.flatten()]\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                             cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "        classes = sorted(list(Counter(y)))\n",
    "        len_arr = len(classes)\n",
    "        labels = [f\"{v1}\\n{v2}\\n\" for v1, v2 in\n",
    "                  zip(group_counts,group_percentages)]\n",
    "        labels = np.asarray(labels).reshape(len_arr,len_arr)\n",
    "        matrix = sns.heatmap( cf_matrix, annot=labels, fmt='', cmap='Blues', ax=axes[num[0], num[1]])\n",
    "        title = matrix.set_title(df[\"Biomarker\"][i], fontsize=10);\n",
    "        matrix.set_xlabel('\\nPredicted Category')\n",
    "        matrix.set_ylabel('Actual Category ');\n",
    "        ## Ticket labels - List must be in alphabetical order\n",
    "        matrix.xaxis.set_ticklabels(classes)\n",
    "        matrix.yaxis.set_ticklabels(classes)\n",
    "        title.set_y(1.2)\n",
    "        fig.subplots_adjust(right =1.6, top=1.2) \n",
    "        plt.tight_layout()\n",
    "        fig.tight_layout()\n",
    "        plt.savefig('Confusion_matrix.jpg')\n",
    "\n",
    "def boxplots_fun(bm_list):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "    lista_prueba = [[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [1, 0], [1, 1], [1, 2], [1, 3], [1, 4]]\n",
    "    for i,num in zip(bm_list, lista_prueba):\n",
    "        a = df[[\"Diagnosis_simplified\", i]]\n",
    "        a = a.dropna()\n",
    "        values = a[\"Diagnosis_simplified\"].value_counts().to_string()\n",
    "        values = values.replace(\"     \", ':') \n",
    "        values =  values.replace(\"\\n\", \" \" )\n",
    "        label = \"Diagnosis:  \" +str(values)\n",
    "        x_ordered = a[\"Diagnosis_simplified\"].sort_values()\n",
    "        ax = sns.boxplot(x=x_ordered,  y=i,  data=df, ax=axes[num[0], num[1]])\n",
    "        #ax.set_xlabel(label)\n",
    "        medians = a[\"Diagnosis_simplified\"].value_counts()\n",
    "        for xtick in ax.get_xticks():\n",
    "            ax.text(xtick,medians[xtick],medians[xtick], \n",
    "                    horizontalalignment='center', verticalalignment=\"top\", size='medium', in_layout=True, color='black',weight='semibold')\n",
    "        add_stat_annotation(ax, data=df, x = \"Diagnosis_simplified\", y=i,\n",
    "                            box_pairs=[(\"HB\", \"HCC\"), (\"HB\", \"NOS\"),(\"HCC\", \"NOS\")],\n",
    "                            test='Mann-Whitney', text_format='star', loc='outside', verbose=2)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2f265",
   "metadata": {},
   "source": [
    "### Top biomarkers. Feature ranking based on logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsets = pd.DataFrame()\n",
    "features_list = []\n",
    "list_of_dicts = []\n",
    "dictionary = {}\n",
    "for var in tqdm(df_top_LFC.columns.tolist()[:-1]):\n",
    "    a = df[[\"Diagnosis_simplified\", var ]]\n",
    "    a = a.dropna()\n",
    "    X = a.drop('Diagnosis_simplified', axis=1)\n",
    "    y = a['Diagnosis_simplified']\n",
    "    #Convert to array\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    y[(y == \"NOS\") | (y == \"HCC\")] = \"Other\"\n",
    "    features_list.append([var, Logistic_Regression_fun(X, y)[0]])\n",
    "df_top_bk = pd.DataFrame(features_list, columns=[\"Biomarker\", \"F1_score\"])\n",
    "top_bk = df_top_bk.sort_values([\"F1_score\"], ascending= False).head(10)\n",
    "top_bk = top_bk[\"Biomarker\"].tolist()\n",
    "\n",
    "top_bk_combinations = combinations_fun(top_bk)\n",
    "\n",
    "\n",
    "for x in tqdm(top_bk_combinations):\n",
    "    if \"Diagnosis_simplified\" in x:\n",
    "        x.remove(\"Diagnosis_simplified\")\n",
    "    x.append(\"Diagnosis_simplified\")\n",
    "    a = df[x]\n",
    "    a = a.dropna()\n",
    "    if a.shape[0] > 0:\n",
    "        values = a[\"Diagnosis_simplified\"].value_counts().to_string()\n",
    "        values = values.replace(\"     \", ':') \n",
    "        values =  values.replace(\"\\n\", \" \" )\n",
    "        N = len(a)\n",
    "        X = a.drop('Diagnosis_simplified', axis=1)\n",
    "        y = a['Diagnosis_simplified']\n",
    "        name = a.drop('Diagnosis_simplified', axis=1).columns.tolist()\n",
    "        name_bsc = [dict_genes[x] for x in name]\n",
    "        #Convert to array\n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        y[(y == \"NOS\") | (y == \"HCC\")] = \"Other\"\n",
    "    dictionary = {'Biomarker': name_bsc, 'f1_score': Logistic_Regression_fun(X,y)[0],\\\n",
    "                  'Precision_score': Logistic_Regression_fun(X,y)[1], \\\n",
    "                  'Recall_score': Logistic_Regression_fun(X,y)[2], \\\n",
    "                     \"N\": N, \"Diagnosis\":values, \"y_true\":Logistic_Regression_fun(X,y)[3],\\\n",
    "                  \"y_pred\":Logistic_Regression_fun(X,y)[4] }\n",
    "    list_of_dicts.append(dictionary)\n",
    "\n",
    "       \n",
    "df_subsets = pd.DataFrame.from_dict(list_of_dicts)\n",
    "df_subsets = df_subsets.sort_values([\"f1_score\"], ascending= False).head(10)\n",
    "df_subsets[[\"Biomarker\", \"f1_score\",'Precision_score', 'Recall_score',  \"N\", \"Diagnosis\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f2eda5",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b121af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsets = df_subsets.reset_index()\n",
    "df_subsets = df_subsets.drop(\"index\", axis=1)\n",
    "confusion_matrix_fun(df_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd0261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e928b843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e6911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb71a2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
